{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import sklearn.metrics as metrics\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.modules.loss as loss\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import data\n",
    "import my\n",
    "import lenet\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scores(c, loader):\n",
    "    keys = ('accuracy', 'precision', 'recall', 'f1')\n",
    "    scores = (\n",
    "        metrics.accuracy_score,\n",
    "        lambda y, y_bar: metrics.precision_score(y, y_bar, average='micro'),\n",
    "        lambda y, y_bar: metrics.recall_score(y, y_bar, average='micro'),\n",
    "        lambda y, y_bar: metrics.f1_score(y, y_bar, average='micro'),\n",
    "    )\n",
    "    values = [value.item() for value in my.global_scores(c, loader, scores)]\n",
    "    return collections.OrderedDict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = data.load_cifar10(rbg=True, torch=True)\n",
    "\n",
    "train_set = utils.data.TensorDataset(train_x, train_y)\n",
    "train_loader = utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_set = utils.data.TensorDataset(test_x, test_y)\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=4096)\n",
    "\n",
    "n_classes = int(train_y.max() - train_y.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = lenet.LeNet(3, n_classes)\n",
    "# c = lenet.LeNet(3, n_classes, nonlinear=F.relu)\n",
    "# c = resnet.ResNet(18, n_classes)\n",
    "cuda = True # always GPU 0\n",
    "if cuda:\n",
    "    c.cuda()\n",
    "optimizer = optim.SGD(c.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = optim.Adam(c.parameters())\n",
    "\n",
    "for key, value in global_scores(c, test_loader).items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "for i in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        ce = loss.CrossEntropyLoss()(c(x), y)\n",
    "        optimizer.zero_grad()\n",
    "        ce.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_scores = global_scores(c, train_loader)\n",
    "    test_scores = global_scores(c, test_loader)\n",
    "    print('[epoch %d]' % (i + 1) + \\\n",
    "          ' | '.join('%s %0.3f/%0.3f' % (key, value, test_scores[key])for key, value in train_scores.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th.save(c.state_dict(), 'cifar10-resnet18')\n",
    "# th.save(c.state_dict(), 'cifar10-1-9-resnet18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## LeNet\n",
    "\n",
    "## ResNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
