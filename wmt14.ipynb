{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext as thtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.c_size = 1024\n",
    "args.de_h_size = 1024\n",
    "args.en_h_size = 1024\n",
    "args.gpu = 0\n",
    "args.h_size = 1024\n",
    "args.max_len = 10\n",
    "args.n_epochs = 10\n",
    "args.p_teacher = 0.5\n",
    "args.s_size = 1024\n",
    "args.shrink_size = 1024\n",
    "args.src_e_size = 1024\n",
    "args.trg_e_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu < 0:\n",
    "    cuda = False\n",
    "    device = th.device('cpu')\n",
    "else:\n",
    "    cuda = True\n",
    "    device = th.device('cuda', args.gpu)\n",
    "    th.cuda.set_device(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO train/dev/test\n",
    "sf = thtext.data.Field(tokenize=thtext.data.utils.get_tokenizer('moses'))\n",
    "tf = thtext.data.Field(tokenize=thtext.data.utils.get_tokenizer('moses'))\n",
    "wmt14 = thtext.datasets.WMT14('WMT14/newstest2009', ('.de', '.en'), (sf, tf))\n",
    "sf.build_vocab(wmt14)\n",
    "tf.build_vocab(wmt14)\n",
    "sort_key = lambda x: thtext.data.interleave_keys(len(x.src), len(x.trg))\n",
    "train_loader = thtext.data.BucketIterator(wmt14, batch_size=32, sort_key=sort_key)\n",
    "sos_token = len(tf.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, v_size, e_size, h_size, c_size):\n",
    "        super().__init__()\n",
    "        self.h_size = h_size\n",
    "\n",
    "        self.embedding = nn.Embedding(v_size, e_size)\n",
    "        self.gru = nn.GRU(e_size, h_size)\n",
    "        self.v = nn.Parameter(th.randn(1, h_size, c_size))\n",
    "\n",
    "    def forward(self, src):\n",
    "        embeded = self.embedding(src)\n",
    "        h = th.zeros(1, src.size(1), self.h_size, device=device)\n",
    "        _, h = self.gru(embeded, h)\n",
    "        c = th.tanh(th.bmm(h, self.v))\n",
    "        return c\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, c_size, h_size, v_size, e_size, s_size, shrinked_size):\n",
    "        super().__init__()\n",
    "        self.v = nn.Parameter(th.randn(1, c_size, h_size))\n",
    "        self.embedding = nn.Embedding(v_size, e_size)\n",
    "        self.gru = nn.GRU(e_size, h_size)\n",
    "        self.linear_h0, self.linear_h1 = nn.Linear(h_size, s_size), nn.Linear(h_size, s_size)\n",
    "        self.linear_y0, self.linear_y1 = nn.Linear(e_size, s_size), nn.Linear(e_size, s_size) # TODO embedded?\n",
    "        self.linear_c0, self.linear_c1 = nn.Linear(c_size, s_size), nn.Linear(c_size, s_size)\n",
    "        self.linear_shrink = nn.Linear(s_size, shrinked_size)\n",
    "        self.linear = nn.Linear(shrinked_size, v_size)\n",
    "\n",
    "    def forward(self, y, h, c):\n",
    "        if h is None:\n",
    "            h = th.tanh(th.bmm(c, self.v))\n",
    "        y = self.embedding(y)\n",
    "        _, h = self.gru(y.unsqueeze(0), h)\n",
    "        h_squeezed = th.squeeze(h)\n",
    "        c = th.squeeze(c)\n",
    "        s0 = self.linear_h0(h_squeezed) + self.linear_y0(y) + self.linear_c0(c) # TODO embedded?\n",
    "        s1 = self.linear_h1(h_squeezed) + self.linear_y1(y) + self.linear_c1(c) # TODO embedded?\n",
    "        s = th.max(s0, s1)\n",
    "        y = self.linear(self.linear_shrink(s))\n",
    "        return y, h\n",
    "\n",
    "# TODO\n",
    "class AttnDecoder(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(sf.vocab.itos), args.src_e_size, args.en_h_size, args.c_size)\n",
    "decoder = Decoder(args.c_size, args.de_h_size, len(tf.vocab.itos) + 1, args.trg_e_size, args.s_size, args.shrink_size)\n",
    "if cuda:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "en_optim = optim.SGD(encoder.parameters(), 1e-3)\n",
    "de_optim = optim.SGD(decoder.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.n_epochs):\n",
    "    for j, b in enumerate(train_loader):\n",
    "        c = encoder(b.src)\n",
    "\n",
    "        sos = th.full((b.trg.size(1),), sos_token, dtype=th.long, device=device)\n",
    "        h = None\n",
    "        objective = 0\n",
    "        for k, t in enumerate(b.trg):\n",
    "            if random.random() < args.p_teacher:\n",
    "                y, h = decoder(b.trg[k - 1] if k > 0 else sos, h, c)\n",
    "            else:\n",
    "                y, h = decoder(th.max(y, 1)[1].squeeze() if k > 0 else sos, h, c)\n",
    "            objective += F.nll_loss(F.log_softmax(y, 1), t)\n",
    "        objective /= k + 1\n",
    "        en_optim.zero_grad()\n",
    "        de_optim.zero_grad()\n",
    "        objective.backward()\n",
    "        en_optim.step()\n",
    "        de_optim.step()\n",
    "        print('[iteration %d]%f' % (j, objective))        \n",
    "#         break\n",
    "        \n",
    "    print('[epoch %d]%f' % (i, objective))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
