{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import tensorboardX as tb\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import data\n",
    "import lenet\n",
    "import my\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.actor = 'linear'\n",
    "args.avg = 'binary' # average\n",
    "args.bsa = 100 # batch size of actor\n",
    "args.ckpt_id = \"parameter\" \\\n",
    "\"#actor:linear#avg:binary#bsa:100#bscx:1#bscy:1#ds:cifar10#iw:none#lbl:91#lra:0.001#lrc:0.001#ni:10000#nia:1#nic:25#np:25#ssc:1#std:7.5#tau:0.1-actor-1000\"\n",
    "args.ds = 'cifar10' # data set\n",
    "args.gpu = 0\n",
    "args.lbl = '91' # labelling\n",
    "args.np = 25 # number of perturbations\n",
    "# args.p = 'a' # perturbation: actor\n",
    "args.p = 'p' # perturbation: parameter\n",
    "args.std = 0.1\n",
    "args.tensorboard = True\n",
    "\n",
    "keys = sorted(vars(args).keys())\n",
    "excluded = ['ckpt_id', 'gpu', 'tensorboard']\n",
    "experiment_id = 'perturbation#' + '#'.join('%s:%s' % (key, str(getattr(args, key))) for key in keys if key not in excluded)\n",
    "if args.tensorboard:\n",
    "    writer = tb.SummaryWriter('runs/' + experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu < 0:\n",
    "    cuda = False\n",
    "    new_tensor = th.FloatTensor\n",
    "else:\n",
    "    cuda = True\n",
    "    new_tensor = th.cuda.FloatTensor\n",
    "    th.cuda.set_device(args.gpu)\n",
    "\n",
    "labelling = {} if args.lbl == '' else {(0, 9) : 0, (9, 10) : 1}\n",
    "rbg = args.actor in ('lenet', 'resnet')\n",
    "train_x, train_y, test_x, test_y = getattr(data, 'load_%s' % args.ds)(labelling, rbg, torch=True)\n",
    "\n",
    "train_set = utils.data.TensorDataset(train_x, train_y)\n",
    "train_loader = utils.data.DataLoader(train_set, 4096, drop_last=False)\n",
    "test_set = utils.data.TensorDataset(test_x, test_y)\n",
    "test_loader = utils.data.DataLoader(test_set, 4096, drop_last=False)\n",
    "\n",
    "loader = data.BalancedDataLoader(train_x, train_y, args.bsa, cuda)\n",
    "\n",
    "n_classes = int(train_y.max() - train_y.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scores(c, loader):\n",
    "    key_list = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    score_list = [\n",
    "        metrics.accuracy_score,\n",
    "        lambda y, y_bar: metrics.precision_recall_fscore_support(y, y_bar, average=args.avg)\n",
    "    ]\n",
    "    accuracy, (precision, recall, f1, _) = my.global_scores(c, loader, score_list)\n",
    "    return collections.OrderedDict({\n",
    "        'accuracy'  : accuracy,\n",
    "        'precision' : precision,\n",
    "        'recall'    : recall,\n",
    "        'f1'        : f1,\n",
    "    })\n",
    "\n",
    "def report(actor, i):\n",
    "    train_scores = global_scores(actor, train_loader)\n",
    "    test_scores = global_scores(actor, test_loader)\n",
    "\n",
    "    prefix = '0' * (len(str(args.np)) - len(str(i + 1)))\n",
    "    print('[iteration %s%d]' % (prefix, i + 1) + \\\n",
    "          ' | '.join('%s %0.3f/%0.3f' % (key, value, test_scores[key]) for key, value in train_scores.items()))\n",
    "\n",
    "    if args.tensorboard:\n",
    "        for key, value in train_scores.items():\n",
    "            writer.add_scalar('train-' + key, value, i + 1)\n",
    "        for key, value in test_scores.items():\n",
    "            writer.add_scalar('test-' + key, value, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.random.manual_seed(1)\n",
    "if cuda:\n",
    "    th.cuda.manual_seed_all(1)\n",
    "\n",
    "n_channels = 1 if args.ds == 'mnist' else 3\n",
    "size = 28 if args.ds == 'mnist' else 32\n",
    "actor = {\n",
    "    'linear' : nn.Linear(n_channels * size ** 2, n_classes),\n",
    "    'lenet'  : lenet.LeNet(3, n_classes, size),\n",
    "    'resnet' : resnet.ResNet(depth=18, n_classes=n_classes),\n",
    "}[args.actor]\n",
    "if args.ckpt_id:\n",
    "    actor.load_state_dict(th.load('ckpt/' + args.ckpt_id))\n",
    "my.set_requires_grad(actor, False)\n",
    "if cuda:\n",
    "    actor.cuda()\n",
    "\n",
    "report(actor, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.np):\n",
    "    x, y = next(loader)\n",
    "    if args.p == 'p':\n",
    "        my.perturb(actor, args.std)\n",
    "    z = actor(x)\n",
    "    if args.p == 'a':\n",
    "        z = z + args.std * th.randn(z.shape, device=z.device)\n",
    "    y_bar = th.max(z, 1)[1]\n",
    "    \n",
    "#     statistics = metrics.precision_recall_fscore_support(y, y_bar)\n",
    "#     statistics = map(np.ndarray.tolist, statistics)\n",
    "#     statistics = zip(*statistics)\n",
    "#     for j, s in enumerate(statistics):\n",
    "#         precision, recall, f1_score, support = s\n",
    "#         writer.add_scalar('precision-%d' % j, precision, i + 1)\n",
    "#         writer.add_scalar('recall-%d' % j, recall, i + 1)\n",
    "#         writer.add_scalar('f1_score-%d' % j, f1_score, i + 1)\n",
    "#         writer.add_scalar('support-%d' % j, support, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y, y_bar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
