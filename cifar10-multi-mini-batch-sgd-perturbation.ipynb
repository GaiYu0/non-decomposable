{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import copy\n",
    "import itertools as it\n",
    "import pickle\n",
    "import time\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.loss import CrossEntropyLoss, MSELoss\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "if cuda:\n",
    "    th.cuda.set_device(1)\n",
    "\n",
    "th.random.manual_seed(1)\n",
    "if cuda:\n",
    "    th.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = my.load_cifar10(rbg=True)\n",
    "\n",
    "train_x = th.from_numpy(train_x).float()\n",
    "train_y = th.from_numpy(train_y)\n",
    "test_x = th.from_numpy(test_x).float()\n",
    "test_y = th.from_numpy(test_y)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y), 1024 * 4, drop_last=False)\n",
    "test_loader = DataLoader(TensorDataset(test_x, test_y), 1024 * 4, drop_last=False)\n",
    "\n",
    "n_classes = int(train_y.max() - train_y.min() + 1)\n",
    "\n",
    "dataset = TensorDataset(train_x, train_y)\n",
    "\n",
    "def sample(sample_size, batch_size):\n",
    "    dl = DataLoader(dataset, sample_size, shuffle=True)\n",
    "    s = it.takewhile(lambda x: x[0] < batch_size, enumerate(dl))\n",
    "    s = [(Variable(x), Variable(y)) for _, (x, y) in s]\n",
    "    if cuda:\n",
    "        s = [(x.cuda(), y.cuda()) for (x, y) in s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 2, 1)\n",
    "        self.linear = nn.Linear(8, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 8)\n",
    "        x = self.linear(x.view(-1, 8))\n",
    "        return x    \n",
    "    \n",
    "def forward(classifier, xy):\n",
    "    x, y = xy\n",
    "    y = my.onehot(y, n_classes)\n",
    "    y_bar = F.softmax(classifier(x), 1)\n",
    "    return th.cat((y, y_bar), 1).view(1, -1)\n",
    "\n",
    "L = lambda c, loader: my.global_stats(c, loader, my.nd_curry(my.nd_f_beta, n_classes))\n",
    "\n",
    "def L_mini_batch(c, loader):\n",
    "    L_list = [my.nd_f_beta(my.predict(c, x), y, n_classes) for x, y in loader]\n",
    "    return th.cat(L_list).view(-1, 1)\n",
    "\n",
    "def sgd_perturb(c, s, n):\n",
    "    c = copy.deepcopy(c)\n",
    "    optim = Adam(c.parameters(), 1e-3)\n",
    "    p_list = []\n",
    "    for _ in range(n):\n",
    "        ce = sum(F.nll_loss(F.log_softmax(c(x), 1), y) for x, y in s) / len(s)\n",
    "        optim.zero_grad()\n",
    "        ce.backward()\n",
    "        optim.step()\n",
    "        p_list.append(copy.deepcopy(c))\n",
    "    return p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "sample_size = 50\n",
    "\n",
    "c = CNN(n_classes)\n",
    "critic = my.RN(sample_size, 2 * n_classes, (32, 64), (64,) * 1 + (1,), F.relu)\n",
    "if cuda:\n",
    "    c.cuda()\n",
    "    critic.cuda()\n",
    "c_optim = Adam(c.parameters(), 1e-3)\n",
    "critic_optim = Adam(critic.parameters(), 1e-3)\n",
    "\n",
    "'initial f1: %f' % L(c, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 50\n",
    "n_perturbations = 50\n",
    "n_sgd_perturbations = 10\n",
    "actor_iterations = 10\n",
    "critic_iterations = 10\n",
    "std = 1e-1\n",
    "tau = 1e-2\n",
    "\n",
    "hist = []\n",
    "for i in range(n_iterations):\n",
    "    hist.append({})\n",
    "#   hist[-1]['c_state_dict'] = copy.deepcopy(my.state_dict_gpu2cpu(c.state_dict()))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        s = sample(sample_size, batch_size)\n",
    "#   hist[-1]['s'] = s\n",
    "\n",
    "    L_c = L_mini_batch(c, s)\n",
    "    c_bar_list = []\n",
    "    L_bar_list = []\n",
    "    t_list = []\n",
    "    p_list = sgd_perturb(c, s, n_sgd_perturbations)\n",
    "    for j in range(n_perturbations):\n",
    "        if p_list:\n",
    "            c_bar_list.append(p_list.pop())\n",
    "        else:\n",
    "            c_bar_list.append(my.perturb(c, std))\n",
    "        L_bar = L_mini_batch(c_bar_list[-1], s)\n",
    "        L_bar_list.append(L_bar)\n",
    "        t_list.append(L_c - L_bar)\n",
    "    w_list = th.cat([th.exp(t**2 / tau) for t in t_list], 1)\n",
    "    w_list = th.chunk((w_list / th.sum(w_list, 1, keepdim=True)).detach(), n_perturbations, 1)\n",
    "\n",
    "    hist[-1]['L_bar_list'] = L_bar_list\n",
    "    hist[-1]['w_list'] = w_list\n",
    "\n",
    "    y = th.cat([forward(c, xy) for xy in s], 0).detach()\n",
    "    y_bar_list = [th.cat([forward(c_bar, xy) for xy in s], 0).detach() \\\n",
    "                  for c_bar in c_bar_list]\n",
    "    for j in range(critic_iterations):\n",
    "        for y_bar, t, w in zip(y_bar_list, t_list, w_list):\n",
    "            delta = critic(y) - critic(y_bar)\n",
    "            mse = th.sum(w * (t - delta) ** 2)\n",
    "            critic_optim.zero_grad()\n",
    "            mse.backward()\n",
    "            critic_optim.step()\n",
    "\n",
    "#     hist[-1]['critic_state_dict'] = copy.deepcopy(my.state_dict_gpu2cpu(critic.state_dict()))\n",
    "\n",
    "    c_param = copy.deepcopy(tuple(c.parameters()))\n",
    "    for j in range(actor_iterations):\n",
    "        y_bar = th.cat([forward(c, xy) for xy in s], 0)\n",
    "        objective = -th.mean(critic(y_bar))\n",
    "        c_optim.zero_grad()\n",
    "        objective.backward()\n",
    "        c_optim.step()\n",
    "        if any(float(th.max(th.abs(p - q))) > std for p, q in zip(c_param, c.parameters())):\n",
    "            break\n",
    "\n",
    "    if (i + 1) % 1 == 0:\n",
    "        f1 = L(c, test_loader)\n",
    "        hist[-1]['f1'] = float(f1)\n",
    "        print('[iteration %d]f1: %f' % (i + 1, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(range(len(hist)), (-math.log(1 / n_perturbations),) * len(hist))\n",
    "entropy_list = []\n",
    "for i, h in enumerate(hist):\n",
    "    w_list = th.cat(h['w_list'], 1)\n",
    "    entropy_list.append(-th.sum(w_list * th.log(w_list), 1))\n",
    "    pl.plot((i,) * batch_size, entropy_list[-1].data.cpu().numpy(), 'bx')\n",
    "\n",
    "tolist = lambda x: th.cat(x, 1).data.cpu().numpy().flatten()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    pl.figure()\n",
    "    pl.plot(range(len(hist)), tolist([e[i : i + 1].view(1, 1) for e in entropy_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in enumerate(hist):\n",
    "    pl.plot((i,) * batch_size * n_perturbations, tolist(h['L_bar_list']), 'bx')\n",
    "for i in range(batch_size):\n",
    "    pl.figure()\n",
    "    for j, h in enumerate(hist):\n",
    "        pl.plot((j,) * n_perturbations, tolist([L_bar[i : i + 1] for L_bar in h['L_bar_list']]), 'bx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
