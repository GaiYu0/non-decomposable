{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import sklearn.metrics as metrics\n",
    "import tensorboardX as tb\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.modules.loss as loss\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import data\n",
    "import my\n",
    "import lenet\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.batch_size = 50\n",
    "args.gpu = 1\n",
    "args.log_every = 1000\n",
    "args.n_iterations = 50000\n",
    "\n",
    "keys = sorted(vars(args).keys())\n",
    "excluded = ('gpu',)\n",
    "run_id = 'relabelled-ce-' + '-'.join('%s-%s' % (key, str(getattr(args, key))) for key in keys if key not in excluded)\n",
    "writer = tb.SummaryWriter('runs/' + run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu < 0:\n",
    "    cuda = False\n",
    "else:\n",
    "    cuda = True\n",
    "    th.cuda.set_device(args.gpu)\n",
    "\n",
    "labelling = {(0, 9) : 0, (9, 10) : 1}\n",
    "# labelling = {(0, 5) : 0, (5, 6) : 1, (6, 7) : 2, (7, 8) : 3, (8, 9) : 4, (9, 10) : 5}\n",
    "train_x, train_y, test_x, test_y = data.load_cifar10(labelling, rbg=True, torch=True)\n",
    "\n",
    "train_set = utils.data.TensorDataset(train_x, train_y)\n",
    "train_loader = utils.data.DataLoader(train_set, 4096, drop_last=False)\n",
    "test_set = utils.data.TensorDataset(test_x, test_y)\n",
    "test_loader = utils.data.DataLoader(test_set, 4096, drop_last=False)\n",
    "\n",
    "def TrainLoader():\n",
    "    dataset = utils.data.TensorDataset(train_x, train_y)\n",
    "    new_loader = lambda: iter(utils.data.DataLoader(dataset, args.batch_size, shuffle=True))\n",
    "    contextualize = lambda x, y: (x.cuda(), y.cuda()) if cuda else (x, y)\n",
    "    while True:\n",
    "        try:\n",
    "            yield contextualize(*next(loader))\n",
    "        except:\n",
    "            loader = new_loader()\n",
    "            yield contextualize(*next(loader))\n",
    "\n",
    "loader = TrainLoader()\n",
    "\n",
    "n_classes = int(train_y.max() - train_y.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scores(c, loader):\n",
    "    keys = ('accuracy', 'precision', 'recall', 'f1')\n",
    "    scores = (\n",
    "        metrics.accuracy_score,\n",
    "        lambda y, y_bar: metrics.precision_score(y, y_bar, average='macro'),\n",
    "        lambda y, y_bar: metrics.recall_score(y, y_bar, average='macro'),\n",
    "        lambda y, y_bar: metrics.f1_score(y, y_bar, average='macro'),\n",
    "    )\n",
    "    values = [value.item() for value in my.global_scores(c, loader, scores)]\n",
    "    return collections.OrderedDict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6848\n",
      "precision 0.5253333333333333\n",
      "recall 0.511299667988001\n",
      "f1 0.48839128665436204\n"
     ]
    }
   ],
   "source": [
    "# c = lenet.LeNet(3, n_classes)\n",
    "c = resnet.ResNet(18, n_classes)\n",
    "\n",
    "if cuda:\n",
    "    c.cuda()\n",
    "    \n",
    "# optimizer = optim.SGD(c.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(c.parameters())\n",
    "\n",
    "for key, value in global_scores(c, test_loader).items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 01000]accuracy 0.947/0.944 | precision 0.779/0.774 | recall 0.901/0.886 | f1 0.827/0.818\n",
      "[iteration 02000]accuracy 0.958/0.953 | precision 0.876/0.866 | recall 0.885/0.871 | f1 0.881/0.869\n",
      "[iteration 03000]accuracy 0.971/0.966 | precision 0.904/0.886 | recall 0.933/0.921 | f1 0.918/0.903\n",
      "[iteration 04000]accuracy 0.977/0.971 | precision 0.940/0.914 | recall 0.934/0.922 | f1 0.937/0.918\n",
      "[iteration 05000]accuracy 0.978/0.970 | precision 0.908/0.879 | recall 0.965/0.944 | f1 0.934/0.909\n",
      "[iteration 06000]accuracy 0.983/0.972 | precision 0.945/0.911 | recall 0.958/0.930 | f1 0.951/0.920\n",
      "[iteration 07000]accuracy 0.987/0.975 | precision 0.948/0.909 | recall 0.976/0.950 | f1 0.961/0.928\n",
      "[iteration 08000]accuracy 0.988/0.974 | precision 0.952/0.903 | recall 0.979/0.948 | f1 0.965/0.924\n",
      "[iteration 09000]accuracy 0.991/0.976 | precision 0.963/0.910 | recall 0.986/0.952 | f1 0.974/0.929\n",
      "[iteration 10000]accuracy 0.990/0.973 | precision 0.977/0.922 | recall 0.971/0.929 | f1 0.974/0.925\n",
      "[iteration 11000]accuracy 0.991/0.973 | precision 0.988/0.936 | recall 0.964/0.916 | f1 0.976/0.926\n",
      "[iteration 12000]accuracy 0.994/0.976 | precision 0.981/0.917 | recall 0.989/0.944 | f1 0.985/0.930\n",
      "[iteration 13000]accuracy 0.995/0.973 | precision 0.985/0.916 | recall 0.985/0.931 | f1 0.985/0.923\n",
      "[iteration 14000]accuracy 0.994/0.973 | precision 0.975/0.906 | recall 0.991/0.940 | f1 0.983/0.923\n",
      "[iteration 15000]accuracy 0.993/0.970 | precision 0.975/0.898 | recall 0.984/0.932 | f1 0.979/0.914\n",
      "[iteration 16000]accuracy 0.998/0.976 | precision 0.997/0.932 | recall 0.992/0.933 | f1 0.994/0.932\n",
      "[iteration 17000]accuracy 0.997/0.973 | precision 0.993/0.925 | recall 0.988/0.925 | f1 0.991/0.925\n",
      "[iteration 18000]accuracy 0.995/0.974 | precision 0.994/0.932 | recall 0.980/0.924 | f1 0.987/0.928\n",
      "[iteration 19000]accuracy 0.997/0.976 | precision 0.994/0.930 | recall 0.990/0.936 | f1 0.992/0.933\n",
      "[iteration 20000]accuracy 0.997/0.973 | precision 0.992/0.913 | recall 0.990/0.934 | f1 0.991/0.923\n",
      "[iteration 21000]accuracy 0.996/0.972 | precision 0.996/0.934 | recall 0.981/0.912 | f1 0.988/0.923\n",
      "[iteration 22000]accuracy 0.998/0.975 | precision 0.996/0.924 | recall 0.992/0.934 | f1 0.994/0.929\n",
      "[iteration 23000]accuracy 0.995/0.972 | precision 0.996/0.937 | recall 0.979/0.913 | f1 0.987/0.925\n",
      "[iteration 24000]accuracy 0.997/0.974 | precision 0.995/0.924 | recall 0.990/0.929 | f1 0.993/0.926\n",
      "[iteration 25000]accuracy 0.996/0.974 | precision 0.981/0.896 | recall 0.995/0.956 | f1 0.988/0.923\n",
      "[iteration 26000]accuracy 0.998/0.975 | precision 0.996/0.918 | recall 0.996/0.938 | f1 0.996/0.928\n",
      "[iteration 27000]accuracy 0.996/0.973 | precision 0.995/0.932 | recall 0.985/0.921 | f1 0.990/0.926\n",
      "[iteration 28000]accuracy 0.999/0.976 | precision 0.998/0.910 | recall 0.998/0.950 | f1 0.998/0.929\n",
      "[iteration 29000]accuracy 0.996/0.973 | precision 0.996/0.930 | recall 0.985/0.922 | f1 0.990/0.926\n",
      "[iteration 30000]accuracy 0.999/0.976 | precision 0.999/0.928 | recall 0.997/0.936 | f1 0.998/0.932\n",
      "[iteration 31000]accuracy 0.999/0.976 | precision 0.998/0.931 | recall 0.994/0.935 | f1 0.996/0.933\n",
      "[iteration 32000]accuracy 0.999/0.977 | precision 0.997/0.922 | recall 0.996/0.948 | f1 0.996/0.934\n",
      "[iteration 33000]accuracy 0.999/0.976 | precision 0.998/0.917 | recall 0.999/0.947 | f1 0.998/0.931\n",
      "[iteration 34000]accuracy 1.000/0.976 | precision 0.998/0.910 | recall 1.000/0.951 | f1 0.999/0.929\n",
      "[iteration 35000]accuracy 1.000/0.976 | precision 0.999/0.920 | recall 0.998/0.942 | f1 0.999/0.931\n",
      "[iteration 36000]accuracy 0.999/0.975 | precision 0.997/0.914 | recall 0.998/0.944 | f1 0.997/0.928\n",
      "[iteration 37000]accuracy 0.999/0.975 | precision 0.997/0.917 | recall 0.996/0.939 | f1 0.996/0.928\n",
      "[iteration 38000]accuracy 0.999/0.975 | precision 0.994/0.903 | recall 0.998/0.954 | f1 0.996/0.926\n",
      "[iteration 39000]accuracy 1.000/0.976 | precision 0.999/0.924 | recall 0.998/0.941 | f1 0.999/0.932\n",
      "[iteration 40000]accuracy 0.998/0.972 | precision 0.997/0.916 | recall 0.992/0.928 | f1 0.994/0.922\n",
      "[iteration 41000]accuracy 0.999/0.977 | precision 0.997/0.919 | recall 0.998/0.949 | f1 0.997/0.934\n",
      "[iteration 42000]accuracy 0.998/0.974 | precision 0.994/0.910 | recall 0.995/0.942 | f1 0.994/0.925\n",
      "[iteration 43000]accuracy 0.999/0.975 | precision 0.998/0.919 | recall 0.998/0.937 | f1 0.998/0.928\n",
      "[iteration 44000]accuracy 0.999/0.976 | precision 0.998/0.924 | recall 0.998/0.939 | f1 0.998/0.931\n",
      "[iteration 45000]accuracy 1.000/0.973 | precision 1.000/0.917 | recall 0.998/0.932 | f1 0.999/0.924\n",
      "[iteration 46000]accuracy 1.000/0.975 | precision 0.998/0.903 | recall 1.000/0.956 | f1 0.999/0.927\n",
      "[iteration 47000]accuracy 0.999/0.977 | precision 0.999/0.931 | recall 0.998/0.939 | f1 0.999/0.935\n",
      "[iteration 48000]accuracy 1.000/0.977 | precision 0.999/0.915 | recall 1.000/0.952 | f1 0.999/0.932\n",
      "[iteration 49000]accuracy 0.999/0.975 | precision 0.997/0.907 | recall 0.999/0.950 | f1 0.998/0.927\n",
      "[iteration 50000]accuracy 0.999/0.975 | precision 0.996/0.908 | recall 0.998/0.950 | f1 0.997/0.928\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 0\n",
    "for i in range(args.n_iterations):\n",
    "    x, y = next(loader)\n",
    "    ce = loss.CrossEntropyLoss()(c(x), y)\n",
    "    optimizer.zero_grad()\n",
    "    ce.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % args.log_every == 0:\n",
    "        train_scores = global_scores(c, train_loader)\n",
    "        test_scores = global_scores(c, test_loader)\n",
    "\n",
    "        prefix = '0' * (len(str(args.n_iterations)) - len(str(i + 1)))\n",
    "        print('[iteration %s%d]' % (prefix, i + 1) + \\\n",
    "              ' | '.join('%s %0.3f/%0.3f' % (key, value, test_scores[key]) for key, value in train_scores.items()))\n",
    "\n",
    "        for key, value in train_scores.items():\n",
    "            writer.add_scalar('train-' + key, value, i)\n",
    "\n",
    "        for key, value in test_scores.items():\n",
    "            writer.add_scalar('test-' + key, value, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pg in optimizer.param_groups:\n",
    "#     pg['lr'] *= 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
