{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import CrossEntropyLoss, MSELoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_TRAIN, N_TEST = 0, 0\n",
    "train_data, train_labels, test_data, test_labels = my.unbalanced_dataset(\n",
    "    'MNIST', N_TRAIN, N_TEST, pca=True, p=[0, 1, 10])\n",
    "train_data_np, train_labels_np, test_data_np, test_labels_np = \\\n",
    "    train_data, train_labels, test_data, test_labels\n",
    "\n",
    "train_data = th.from_numpy(train_data).float()\n",
    "train_labels = th.from_numpy(train_labels).long()\n",
    "test_data = th.from_numpy(test_data).float()\n",
    "test_labels = th.from_numpy(test_labels).long()\n",
    "\n",
    "cuda = True\n",
    "if cuda:\n",
    "    th.cuda.set_device(3)\n",
    "cudalize = lambda x: x.cuda() if cuda else x\n",
    "    \n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(TensorDataset(train_data, train_labels), BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(test_data, test_labels), BATCH_SIZE)\n",
    "\n",
    "N_FEATURES = train_data.size()[1]\n",
    "N_CLASSES = int(train_labels.max() - train_labels.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = my.MLP((N_FEATURES, N_CLASSES), None)\n",
    "if cuda:\n",
    "    mlp.cuda()\n",
    "optim = Adam(mlp.parameters(), lr=0.001)\n",
    "\n",
    "N_EPOCHS = 5\n",
    "for e in range(N_EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        X, y = Variable(X), Variable(y)\n",
    "        optim.zero_grad()\n",
    "        loss = CrossEntropyLoss()(mlp(X), y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            accuracy = my.accuracy(my.predict(mlp, X), y)\n",
    "            print('[iteration %d]nll loss: %f, accuracy %f' % (i + 1, float(loss), float(accuracy)))\n",
    "        \n",
    "    accuracy, precision, recall, f1 = my.global_stats(mlp, test_loader, (\n",
    "        my.accuracy,\n",
    "        my.nd_curry(my.nd_precision, N_CLASSES),\n",
    "        my.nd_curry(my.nd_recall, N_CLASSES),\n",
    "        my.nd_curry(my.nd_f_beta, N_CLASSES)))\n",
    "    print('[epoch %d]accuracy: %f, precision: %f, recall: %f, f1: %f' % (\n",
    "        e + 1, float(accuracy), float(precision), float(recall), float(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = lambda c, loader: my.global_stats(c, loader, my.nd_curry(my.nd_f_beta, N_CLASSES))\n",
    "\n",
    "def forward(classifier, X, y, std=0):\n",
    "    if cuda:\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "    X, y = Variable(X), Variable(y)\n",
    "    y = my.onehot(y, N_CLASSES)\n",
    "    y_bar = classifier(X)\n",
    "    if std > 0:\n",
    "        noise = th.randn(y_bar.size()) * std\n",
    "        if y_bar.is_cuda:\n",
    "            noise = noise.cuda()\n",
    "        y_bar += Variable(noise)\n",
    "    y_bar = F.softmax(y_bar, 1)\n",
    "    return th.cat((y, y_bar), 1).view(1, -1)\n",
    "\n",
    "create_sample_loader = lambda: iter(DataLoader(TensorDataset(train_data, train_labels),\n",
    "                                               BATCH_SIZE, shuffle=True, drop_last=True))\n",
    "\n",
    "def sample(loader, K):\n",
    "    samples = []\n",
    "    for k in range(K):\n",
    "        try:\n",
    "            samples.append(next(loader))\n",
    "        except StopIteration:\n",
    "            loader = create_sample_loader()\n",
    "            samples.append(next(loader))\n",
    "    return samples, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = my.MLP((N_FEATURES, N_CLASSES), th.tanh)\n",
    "if cuda:\n",
    "    c.cuda()\n",
    "c_optim = SGD(c.parameters(), 1e-1, momentum=0.9)\n",
    "# c_optim = Adam(c.parameters(), 1e-3)\n",
    "\n",
    "SAMPLE_SIZE = 64\n",
    "D = (train_data.size()[1] + N_CLASSES + N_CLASSES) * SAMPLE_SIZE\n",
    "critic = my.MLP(((N_CLASSES + N_CLASSES) * SAMPLE_SIZE,) + (1024,) * 3 + (1,), F.relu)\n",
    "if cuda:\n",
    "    critic.cuda()\n",
    "critic_optim = SGD(critic.parameters(), 1e-3, momentum=0.9)\n",
    "# critic_optim = Adam(critic.parameters(), 1e-3)\n",
    "\n",
    "N = 4096 * 2\n",
    "train_loader = DataLoader(TensorDataset(train_data[:N], train_labels[:N]), N / 2)\n",
    "test_loader = DataLoader(TensorDataset(test_data[:N], test_labels[:N]), N / 2)\n",
    "\n",
    "sample_loader = create_sample_loader()\n",
    "\n",
    "float(L(c, train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "OUTER = 2000\n",
    "INNER = 10\n",
    "STD = 0.1\n",
    "K = 5\n",
    "critic_aware = False\n",
    "tau = 1\n",
    "\n",
    "stats = [{} for _ in range(OUTER)]\n",
    "for i in range(OUTER):\n",
    "    stats[i]['mse'] = []\n",
    "    for j in range(INNER):\n",
    "        c_bar = my.perturb(c, STD)\n",
    "        delta = L(c, train_loader) - L(c_bar, train_loader)\n",
    "        \n",
    "        samples, sample_loader = sample(sample_loader, K)\n",
    "        c_action = th.cat([forward(c, X, y) for X, y in samples], 0)\n",
    "        c_bar_action = th.cat([forward(c_bar, X, y) for X, y in samples], 0)\n",
    "        delta_bar = th.mean(critic(c_action) - critic(c_bar_action), 0)\n",
    "        \n",
    "        mse = MSELoss()(delta_bar, delta)\n",
    "        stats[i]['mse'].append(float(mse))\n",
    "        critic_optim.zero_grad()\n",
    "        mse.backward()\n",
    "        critic_optim.step()\n",
    "        \n",
    "    samples, sample_loader = sample(sample_loader, K)\n",
    "    y_list = [cudalize(y) for X, y in samples]\n",
    "    std = 1 if critic_aware else 0\n",
    "    c_action = [forward(c, X, y, std) for X, y in samples]\n",
    "    if critic_aware:\n",
    "        y_bar_list = [th.max(a.data.view(SAMPLE_SIZE, N_CLASSES * 2)[:, -N_CLASSES:], 1)[1] for a in c_action]\n",
    "        f1 = [my.nd_f_beta(y_bar, y, N_CLASSES) for y_bar, y in zip(y_bar_list, y_list)]\n",
    "        f1 = cudalize(th.from_numpy(np.array(f1)).float())\n",
    "    c_action = th.cat(c_action, 0)\n",
    "    c_action.register_hook(lambda g: stats[i].update({'mean': float(th.mean(g)), 'std': float(th.std(g))}))\n",
    "    f1_bar = critic(c_action)\n",
    "    weight = th.exp(-(Variable(f1) - f1_bar.view(K)) ** 2 / tau).detach() if critic_aware else 1\n",
    "    objective = -th.mean(weight * f1_bar)\n",
    "    c_optim.zero_grad()\n",
    "    objective.backward()\n",
    "    c_optim.step()\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        f1 = L(c, test_loader)\n",
    "        print('[iteration %d]mse: %f, f1: %f' % ((i + 1), float(mse), float(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = my.global_stats(c, test_loader, (\n",
    "    my.accuracy,\n",
    "    my.nd_curry(my.nd_precision, N_CLASSES),\n",
    "    my.nd_curry(my.nd_recall, N_CLASSES),\n",
    "    my.nd_curry(my.nd_f_beta, N_CLASSES)))\n",
    "float(accuracy), float(precision), float(recall), float(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_list = [sum(stat['mse']) / INNER for stat in stats]\n",
    "pl.plot(range(len(mse_list)), mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = [stat['mean'] for stat in stats]\n",
    "pl.figure()\n",
    "pl.xlabel('iteration')\n",
    "pl.ylabel('mean')\n",
    "pl.plot(range(len(means)), means)\n",
    "stds = [stat['std'] for stat in stats]\n",
    "pl.figure()\n",
    "pl.xlabel('iteration')\n",
    "pl.ylabel('std')\n",
    "pl.plot(range(len(stds)), stds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
