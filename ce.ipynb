{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import sklearn.metrics as metrics\n",
    "import tensorboardX as tb\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.modules.loss as loss\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import data\n",
    "import mlp\n",
    "import my\n",
    "import lenet\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.actor = 'mlp'\n",
    "# args.actor = 'lenet'\n",
    "# args.actor = 'resnet'\n",
    "args.average = 'binary'\n",
    "args.batch_size = 1000\n",
    "# args.dataset = 'MNIST'\n",
    "# args.dataset = 'CIFAR10'\n",
    "args.dataset = 'covtype'\n",
    "args.gpu = 1\n",
    "args.post = 'covtype'\n",
    "# args.post = '91-over'\n",
    "# args.post = '91-under'\n",
    "args.lr = 1e-3\n",
    "args.report_every = 1\n",
    "args.n_iterations = 1000\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--actor', type=str, default='linear')\n",
    "parser.add_argument('--average', type=str, default='binary')\n",
    "parser.add_argument('--batch-size', type=int, default=None)\n",
    "parser.add_argument('--dataset', type=str, default='covtype')\n",
    "parser.add_argument('--gpu', type=int, default=None)\n",
    "parser.add_argument('--post', type=str, default='covtype')\n",
    "parser.add_argument('--lr', type=float, default=None)\n",
    "parser.add_argument('--report-every', type=int, default=1)\n",
    "parser.add_argument('--n-iterations', type=int, default=10000)\n",
    "args = parser.parse_args()\n",
    "'''\n",
    "\n",
    "keys = sorted(vars(args).keys())\n",
    "excluded = ('gpu', 'report_every', 'n_iterations')\n",
    "run_id = 'ce-' + '-'.join('%s-%s' % (key, str(getattr(args, key))) for key in keys if key not in excluded)\n",
    "writer = tb.SummaryWriter('runs/' + run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu < 0:\n",
    "    cuda = False\n",
    "else:\n",
    "    cuda = True\n",
    "    th.cuda.set_device(args.gpu)\n",
    "\n",
    "rbg = args.actor in ('lenet', 'resnet')\n",
    "train_x, train_y, test_x, test_y = data.load_dataset(args.dataset, rbg)\n",
    "train_x, test_x = data.normalize(train_x, test_x)\n",
    "if args.post == '91-under':\n",
    "    label2ratio = {0 : 0.9, 1 : 0.1}\n",
    "    train_x, train_y, test_x, test_y = data.random_subset(train_x, train_y, test_x, test_y, label2ratio)\n",
    "elif args.post == '91-over':\n",
    "    label2label = {9 : 1}\n",
    "    label2label.update({i : 0 for i in range(9)})\n",
    "    train_x, train_y, test_x, test_y = data.relabel(train_x, train_y, test_x, test_y, label2label)\n",
    "elif args.post == 'covtype':\n",
    "    label2label = {0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 1, 5 : 0, 6 : 0}\n",
    "    train_x, train_y, test_x, test_y = data.relabel(train_x, train_y, test_x, test_y, label2label)\n",
    "\n",
    "bsl = {\n",
    "    'MNIST'   : 4096,\n",
    "    'CIFAR10' : 4096,\n",
    "    'covtype' : 65536,\n",
    "}[args.dataset] # batch size of loader\n",
    "train_set = utils.data.TensorDataset(train_x, train_y)\n",
    "train_loader = utils.data.DataLoader(train_set, bsl, drop_last=False)\n",
    "test_set = utils.data.TensorDataset(test_x, test_y)\n",
    "test_loader = utils.data.DataLoader(test_set, bsl, drop_last=False)\n",
    "\n",
    "loader = data.BalancedDataLoader(train_x, train_y, args.batch_size, cuda)\n",
    "\n",
    "n_classes = int(train_y.max() - train_y.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scores(c, loader):\n",
    "    key_list = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    score_list = [\n",
    "        metrics.accuracy_score,\n",
    "        lambda y, y_bar: metrics.precision_recall_fscore_support(y, y_bar, average=args.average)\n",
    "    ]\n",
    "    accuracy, (precision, recall, f1, _) = my.global_scores(c, loader, score_list)\n",
    "    return collections.OrderedDict({\n",
    "        'accuracy'  : accuracy,\n",
    "        'precision' : precision,\n",
    "        'recall'    : recall,\n",
    "        'f1'        : f1,\n",
    "    })\n",
    "\n",
    "def report(actor, i):\n",
    "    train_scores = global_scores(actor, train_loader)\n",
    "    test_scores = global_scores(actor, test_loader)\n",
    "\n",
    "    prefix = '0' * (len(str(args.n_iterations)) - len(str(i + 1)))\n",
    "    print('[iteration %s%d]' % (prefix, i + 1) + \\\n",
    "          ' | '.join('%s %0.3f/%0.3f' % (key, value, test_scores[key]) for key, value in train_scores.items()))\n",
    "\n",
    "    for key, value in train_scores.items():\n",
    "        writer.add_scalar('train-' + key, value, i + 1)\n",
    "\n",
    "    for key, value in test_scores.items():\n",
    "        writer.add_scalar('test-' + key, value, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0000]accuracy 0.760/0.541 | precision 0.105/0.311 | recall 0.008/0.011 | f1 0.014/0.022\n"
     ]
    }
   ],
   "source": [
    "if args.dataset in ['MNIST', 'CIFAR10']:\n",
    "    n_channels = {\n",
    "        'MNIST'   : 1,\n",
    "        'CIFAR10' : 3,\n",
    "    }[args.dataset]\n",
    "    size = {\n",
    "        'MNIST'   : 28,\n",
    "        'CIFAR10' : 32,\n",
    "    }[args.dataset]\n",
    "    actor = {\n",
    "        'linear' : nn.Linear(n_channels * size ** 2, n_classes),\n",
    "        'lenet'  : lenet.LeNet(3, n_classes, size),\n",
    "        'resnet' : resnet.ResNet(depth=18, n_classes=n_classes),\n",
    "    }[args.actor]\n",
    "elif args.dataset in ['covtype']:\n",
    "    n_features = train_x.size(1)\n",
    "    actor = {\n",
    "        'linear' : nn.Linear(n_features, n_classes),\n",
    "        'mlp'    : mlp.MLP([n_features, 60, 60, 80, n_classes], th.tanh)\n",
    "    }[args.actor]\n",
    "\n",
    "if cuda:\n",
    "    actor.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(actor.parameters(), lr=args.lr, amsgrad=True)\n",
    "\n",
    "report(actor, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001]accuracy 0.877/0.755 | precision 0.031/0.114 | recall 0.005/0.008 | f1 0.008/0.015\n",
      "[iteration 0002]accuracy 0.950/0.895 | precision 0.008/0.003 | recall 0.004/0.001 | f1 0.005/0.001\n",
      "[iteration 0003]accuracy 0.977/0.971 | precision 0.000/0.000 | recall 0.000/0.000 | f1 0.000/0.000\n",
      "[iteration 0004]accuracy 0.980/0.983 | precision 0.000/0.000 | recall 0.000/0.000 | f1 0.000/0.000\n",
      "[iteration 0005]accuracy 0.982/0.984 | precision 0.000/0.000 | recall 0.000/0.000 | f1 0.000/0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-083927641d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-c6768bb38ad9>\u001b[0m in \u001b[0;36mreport\u001b[0;34m(actor, i)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c6768bb38ad9>\u001b[0m in \u001b[0;36mglobal_scores\u001b[0;34m(c, loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     return collections.OrderedDict({\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m'accuracy'\u001b[0m  \u001b[0;34m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/non-decomposable/my.py\u001b[0m in \u001b[0;36mglobal_scores\u001b[0;34m(module, loader, scores)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_bar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(args.n_iterations):\n",
    "    x, y = next(loader)\n",
    "    ce = loss.CrossEntropyLoss()(actor(x), y)\n",
    "    optimizer.zero_grad()\n",
    "    ce.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % args.report_every == 0:\n",
    "        report(actor, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
