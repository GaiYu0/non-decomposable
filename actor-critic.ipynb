{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import collections\n",
    "import functools\n",
    "import time\n",
    "import sklearn.metrics as metrics\n",
    "import tensorboardX as tb\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import data\n",
    "import guided_es\n",
    "import l1\n",
    "import lenet\n",
    "import mlp\n",
    "import my\n",
    "import nll\n",
    "import resnet\n",
    "import rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.actor = 'mlp'\n",
    "# args.actor = 'lenet'\n",
    "# args.actor = 'resnet'\n",
    "args.alpha = 0.5\n",
    "args.avg = 'binary' # average\n",
    "args.bsa = 500 # batch size of actor\n",
    "args.bscx = 1 # batch size of critic (x)\n",
    "args.bscy = 1 # batch size of critic (y)\n",
    "args.ckpt_every = 100\n",
    "args.cos = False\n",
    "args.critic = 'nll'\n",
    "# args.ds = 'MNIST'\n",
    "# args.ds = 'CIFAR10'\n",
    "args.ds = 'covtype'\n",
    "args.ges = True # guided es\n",
    "args.gpu = 0\n",
    "args.iw = 'none'\n",
    "# args.iw = 'quadratic'\n",
    "args.lra = 1e-3 # learning rate of actor\n",
    "args.lrc = 1e-3 # learning rate of critic\n",
    "args.ni = 1000 # number of iterations\n",
    "args.nia = 1 # number of iterations (actor)\n",
    "args.nic = 25 # number of iterations (critic)\n",
    "args.np = 25 # number of perturbations\n",
    "args.np_ges = 5 # number of perturbations for guided es\n",
    "args.post = 'covtype'\n",
    "# args.post = '91-under'\n",
    "# args.post = '91-over'\n",
    "args.report_every = 1\n",
    "args.resume = 0\n",
    "args.sn = 'p' # source of noise\n",
    "args.ssc = 1 # sample size of critic\n",
    "args.std = 1\n",
    "args.std_ges = 0.1\n",
    "args.tau = 0.1\n",
    "args.tb = True\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--actor', type=str, default='mlp')\n",
    "parser.add_argument('--alpha', type=float, default=0.5)\n",
    "parser.add_argument('--avg', type=str, default='binary')\n",
    "parser.add_argument('--bsa', type=int, default=500)\n",
    "parser.add_argument('--bscx', type=int, default=1)\n",
    "parser.add_argument('--bscy', type=int, default=1)\n",
    "parser.add_argument('--ckpt-every', type=int, default=100)\n",
    "parser.add_argument('--cos', type=bool, default=False)\n",
    "parser.add_argument('--critic', type=str, default='nll')\n",
    "parser.add_argument('--ds', type=str, default='covtype')\n",
    "parser.add_argument('--ges', type=bool, default=None)\n",
    "parser.add_argument('--gpu', type=int, default=None)\n",
    "parser.add_argument('--iw', type=str, default=None)\n",
    "parser.add_argument('--lra', type=float, default=None)\n",
    "parser.add_argument('--lrc', type=float, default=None)\n",
    "parser.add_argument('--ni', type=int, default=100)\n",
    "parser.add_argument('--nia', type=int, default=1)\n",
    "parser.add_argument('--nic', type=int, default=None)\n",
    "parser.add_argument('--np', type=int, default=None)\n",
    "parser.add_argument('--np-ges', type=int, default=1)\n",
    "parser.add_argument('--post', type=str, default='covtype')\n",
    "parser.add_argument('--report-every', type=int, default=100)\n",
    "parser.add_argument('--resume', type=int, default=0)\n",
    "parser.add_argument('--sn', type=str, default=None)\n",
    "parser.add_argument('--ssc', type=int, default=1)\n",
    "parser.add_argument('--std', type=float, default=None)\n",
    "parser.add_argument('--std-ges', type=float, default=None)\n",
    "parser.add_argument('--tau', type=float, default=0.1)\n",
    "parser.add_argument('--tb', type=bool, default=True)\n",
    "args = parser.parse_args()\n",
    "'''\n",
    "\n",
    "keys = sorted(vars(args).keys())\n",
    "excluded = ('ckpt_every', 'gpu', 'report_every', 'ni', 'resume', 'tb')\n",
    "experiment_id = 'ac#' + '#'.join('%s:%s' % (key, str(getattr(args, key))) for key in keys if key not in excluded)\n",
    "if args.tb:\n",
    "    writer = tb.SummaryWriter('runs/' + experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu < 0:\n",
    "    cuda = False\n",
    "    new_tensor = th.FloatTensor\n",
    "else:\n",
    "    cuda = True\n",
    "    new_tensor = th.cuda.FloatTensor\n",
    "    th.cuda.set_device(args.gpu)\n",
    "\n",
    "rbg = args.actor in ('lenet', 'resnet')\n",
    "train_x, train_y, test_x, test_y = data.load_dataset(args.ds, rbg)\n",
    "train_x, test_x = data.normalize(train_x, test_x)\n",
    "if args.post == '91-under':\n",
    "    label2ratio = {0 : 0.9, 1 : 0.1}\n",
    "    train_x, train_y, test_x, test_y = data.random_subset(train_x, train_y, test_x, test_y, label2ratio)\n",
    "elif args.post == '91-over':\n",
    "    label2label = {9 : 1}\n",
    "    label2label.update({i : 0 for i in range(9)})\n",
    "    train_x, train_y, test_x, test_y = data.relabel(train_x, train_y, test_x, test_y, label2label)\n",
    "elif args.post == 'covtype':\n",
    "    label2label = {0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 1, 5 : 0, 6 : 0}\n",
    "    train_x, train_y, test_x, test_y = data.relabel(train_x, train_y, test_x, test_y, label2label)\n",
    "\n",
    "bsl = {\n",
    "    'MNIST'   : 4096,\n",
    "    'CIFAR10' : 4096,\n",
    "    'covtype' : 65536,\n",
    "}[args.ds] # batch size of loader\n",
    "train_set = utils.data.TensorDataset(train_x, train_y)\n",
    "train_loader = utils.data.DataLoader(train_set, bsl, drop_last=False)\n",
    "test_set = utils.data.TensorDataset(test_x, test_y)\n",
    "test_loader = utils.data.DataLoader(test_set, bsl, drop_last=False)\n",
    "\n",
    "loader = data.BalancedDataLoader(train_x, train_y, args.bsa, cuda)\n",
    "\n",
    "n_classes = int(train_y.max() - train_y.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(tensor, bsx, bsy):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : (x, y, z)\n",
    "    \"\"\"\n",
    "    shapex, shapey, shapez = tensor.shape\n",
    "    nx, ny = int(shapex / bsx), int(shapey / bsy)\n",
    "    x_list = th.chunk(tensor, nx, 0)\n",
    "    return sum([[y.view(-1, shapez).contiguous() for y in th.chunk(x, ny, 1)] for x in x_list], [])\n",
    "\n",
    "def forward(actor, xyy, z=None, yz=True, softmax=None, J=None):\n",
    "    xx, yy = zip(*xyy)\n",
    "    x, y = th.cat(xx), th.cat(yy)\n",
    "\n",
    "    ret = []\n",
    "    if z is None:\n",
    "        z = actor(x)\n",
    "        ret.append(z)\n",
    "    if yz:\n",
    "        onehot_x = my.one_hot(y, n_classes)\n",
    "        softmax_x = softmax(z, 1)\n",
    "        cat_x = th.cat([onehot_x, softmax_x], 1)\n",
    "        ret.append(cat_x.view(len(xyy), -1))\n",
    "    if J:\n",
    "        zz = th.chunk(z, len(xyy))\n",
    "        J_x = new_tensor([J(y, z) for y, z in zip(yy, zz)])\n",
    "        ret.append((J_x).unsqueeze(1))\n",
    "    return ret\n",
    "\n",
    "def J(y, z, average=args.avg):\n",
    "    y_bar = th.max(z, 1)[1]\n",
    "    return metrics.f1_score(y, y_bar, average)\n",
    "\n",
    "def surrogate(yz):\n",
    "    yz = th.chunk(yz, int(yz.size(1) / n_classes), 1)\n",
    "    y, z = th.cat(yz[::2]), th.cat(yz[1::2])\n",
    "    return th.norm(y - z, 1)\n",
    "        \n",
    "iw = {\n",
    "    'none' : lambda x: th.zeros_like(x),\n",
    "    'quadratic' : lambda x: x * x,\n",
    "}[args.iw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckpt(actor, critic, actor_optim, critic_optim, i):\n",
    "    th.save(actor.state_dict(), 'ckpt/%s-actor-%d' % (experiment_id, i + 1))\n",
    "    th.save(critic.state_dict(), 'ckpt/%s-critic-%d' % (experiment_id, i + 1))\n",
    "    th.save(actor_optim.state_dict(), 'ckpt/%s-actor_optim-%d' % (experiment_id, i + 1))\n",
    "    th.save(critic_optim.state_dict(), 'ckpt/%s-critic_optim-%d' % (experiment_id, i + 1))\n",
    "\n",
    "def global_scores(c, loader):\n",
    "    key_list = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    score_list = [\n",
    "        metrics.accuracy_score,\n",
    "        lambda y, y_bar: metrics.precision_recall_fscore_support(y, y_bar, average=args.avg)\n",
    "    ]\n",
    "    accuracy, [precision, recall, f1, _] = my.global_scores(c, loader, score_list)\n",
    "    return collections.OrderedDict({\n",
    "        'accuracy'  : accuracy,\n",
    "        'precision' : precision,\n",
    "        'recall'    : recall,\n",
    "        'f1'        : f1,\n",
    "    })\n",
    "\n",
    "def log_critic_stats(critic, i):\n",
    "    if args.critic in ['l1', 'nll']:\n",
    "        w_t = F.softmax(critic.w, 0)\n",
    "        for j, w in enumerate(w_t):\n",
    "            writer.add_scalar('class %d' % j, w, i + 1)\n",
    "            \n",
    "def log_stats(tensor, tag, i):\n",
    "    writer.add_scalar('th.min(%s)' % tag, th.min(tensor), i + 1)\n",
    "    writer.add_scalar('th.max(%s)' % tag, th.max(tensor), i + 1)\n",
    "    writer.add_scalar('th.mean(%s)' % tag, th.mean(tensor), i + 1)\n",
    "    \n",
    "def report(actor, i):\n",
    "    train_scores = global_scores(actor, train_loader)\n",
    "    test_scores = global_scores(actor, test_loader)\n",
    "\n",
    "    prefix = '0' * (len(str(args.ni)) - len(str(i + 1)))\n",
    "    print('[iteration %s%d]' % (prefix, i + 1) + \\\n",
    "          ' | '.join('%s %0.3f/%0.3f' % (key, value, test_scores[key]) for key, value in train_scores.items()))\n",
    "\n",
    "    if args.tb:\n",
    "        for key, value in train_scores.items():\n",
    "            writer.add_scalar('train-' + key, value, i + 1)\n",
    "        for key, value in test_scores.items():\n",
    "            writer.add_scalar('test-' + key, value, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.random.manual_seed(1)\n",
    "if cuda:\n",
    "    th.cuda.manual_seed_all(1)\n",
    "\n",
    "if args.ds in ['MNIST', 'CIFAR10']:\n",
    "    n_channels = {\n",
    "        'MNIST'   : 1,\n",
    "        'CIFAR10' : 3,\n",
    "    }[args.ds]\n",
    "    size = {\n",
    "        'MNIST'   : 28,\n",
    "        'CIFAR10' : 32,\n",
    "    }[args.ds]\n",
    "    actor = {\n",
    "        'linear' : nn.Linear(n_channels * size ** 2, n_classes),\n",
    "        'lenet'  : lenet.LeNet(3, n_classes, size),\n",
    "        'resnet' : resnet.ResNet(depth=18, n_classes=n_classes),\n",
    "    }[args.actor]\n",
    "elif args.ds in ['covtype']:\n",
    "    n_features = train_x.size(1)\n",
    "    actor = {\n",
    "        'linear' : nn.Linear(n_features, n_classes),\n",
    "        'mlp'    : mlp.MLP([n_features, 60, 60, 80, n_classes], th.tanh)\n",
    "    }[args.actor]\n",
    "\n",
    "if args.critic == 'l1':\n",
    "    critic = l1.WeightedL1Loss(n_classes)\n",
    "elif args.critic == 'nll':\n",
    "    critic = nll.WeightedNLLLoss(n_classes)\n",
    "elif args.critic == 'rn':\n",
    "    unary = [2 * n_classes, 256]\n",
    "    binary = [2 * unary[-1], 256]\n",
    "    terminal = [256, 1]\n",
    "    critic = rn.RN(args.bsa, 2 * n_classes, unary, binary, terminal, F.relu, triu=True)\n",
    "\n",
    "if cuda:\n",
    "    actor.cuda()\n",
    "    critic.cuda()\n",
    "\n",
    "actor_bar = copy.deepcopy(actor)\n",
    "my.set_requires_grad(actor_bar, False)\n",
    " \n",
    "actor_opt = optim.Adam(actor.parameters(), lr=args.lra, amsgrad=True)\n",
    "critic_opt = optim.Adam(critic.parameters(), lr=args.lrc, amsgrad=True)\n",
    "\n",
    "if args.resume > 0:\n",
    "    c.load_state_dict(th.load('ckpt/%s-actor-%d' % (experiment_id, args.resume)))\n",
    "    critic.load_state_dict(th.load('ckpt/%s-critic-%d' % (experiment_id, args.resume)))\n",
    "    c_opt.load_state_dict(th.load('ckpt/%s-actor_opt-%d' % (experiment_id, args.resume)))\n",
    "    critic_opt.load_state_dict(th.load('ckpt/%s-critic_opt-%d' % (experiment_id, args.resume)))\n",
    "\n",
    "report(actor, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'softmax' : F.log_softmax, 'J' : J} if args.critic == 'nll' else {'softmax' : F.softmax, 'J' : J}\n",
    "for i in range(args.resume, args.resume + args.ni):\n",
    "    xyy = [next(loader) for j in range(args.ssc)]\n",
    "    \n",
    "    my.set_requires_grad(actor, False)\n",
    "    z, yz, J_x = forward(actor, xyy, **kwargs)\n",
    "\n",
    "    yz_barr, jx_barr, deltaa = [], [], []\n",
    "    for j in range(args.np):\n",
    "        if args.sn == 'a':\n",
    "            epsilon = args.std * th.randn(z.shape, device=z.device)\n",
    "            yz_bar, jx_bar = forward(actor_bar, xyy, z + epsilon, **kwargs)\n",
    "        elif args.sn == 'p':\n",
    "            my.perturb(actor_bar, args.std)\n",
    "            z_bar, yz_bar, jx_bar = forward(actor_bar, xyy, **kwargs)\n",
    "\n",
    "        yz_barr.append(yz_bar)\n",
    "        jx_barr.append(jx_bar)\n",
    "        deltaa.append(J_x - jx_bar)\n",
    "    \n",
    "    if args.tb:\n",
    "        log_stats(th.cat(jx_barr, 1), 'J_bar', i)\n",
    "    \n",
    "    yz_bar = th.cat([yz_bar.unsqueeze(1) for yz_bar in yz_barr], 1)\n",
    "    delta = th.cat(deltaa, 1)\n",
    "    w = F.softmax(iw(delta), 1)\n",
    "    entropy = th.sum(w * th.log(w)) / args.ssc\n",
    "    \n",
    "    if args.tb:\n",
    "        writer.add_scalar('entropy', entropy, i + 1)\n",
    "    \n",
    "    delta, w = delta.unsqueeze(2), w.unsqueeze(2)\n",
    "    partial = functools.partial(batch, bsx=args.bscx, bsy=args.bscy)\n",
    "    yz_barr, deltaa, ww = map(partial, [yz_bar, delta, w])\n",
    "    \n",
    "    my.set_requires_grad(critic, True)\n",
    "    for j in range(args.nic):\n",
    "        for x_yzbar, x_delta, x_w in zip(yz_barr, deltaa, ww):\n",
    "            mse = th.sum(x_w * (x_delta - (critic(yz) - critic(x_yzbar))) ** 2)\n",
    "            critic_opt.zero_grad()\n",
    "            mse.backward()\n",
    "            critic_opt.step()\n",
    "        if args.tb:\n",
    "            writer.add_scalar('mse', mse, i * args.nic + j + 1)\n",
    "    log_critic_stats(critic, i)\n",
    "\n",
    "    my.set_requires_grad(actor, True)\n",
    "    my.set_requires_grad(critic, False)\n",
    "    for j in range(args.nia):\n",
    "        z, yz, J_x = forward(actor, xyy, **kwargs)\n",
    "        \n",
    "        if args.cos:\n",
    "            def hook(g):\n",
    "                g = th.chunk(g, int(g.size(1) / n_classes), 1)\n",
    "                y, z = [th.zeros(g[0].size(), device=g[0].device)] * int(len(g) / 2), g[1::2]\n",
    "                g = th.cat(sum(zip(y, z), tuple()), 1)\n",
    "                globals()['yz_grad'] = g\n",
    "            yz.register_hook(hook)\n",
    "        \n",
    "        if args.tb:\n",
    "            log_stats(J_x, 'J_x', i * args.nia + j)\n",
    "        \n",
    "        objective = -th.mean(critic(yz))\n",
    "        actor_opt.zero_grad()\n",
    "        objective.backward()\n",
    "        \n",
    "        if args.cos:\n",
    "            yz = yz.detach()\n",
    "            yz.requires_grad = True\n",
    "            objective = surrogate(yz)\n",
    "            yz.grad = None\n",
    "            objective.backward()\n",
    "            F.cosine_similarity(yz_grad, yz.grad)\n",
    "        \n",
    "        if args.ges:\n",
    "            partial = lambda actor: forward(actor, xyy, yz=False, **kwargs)[1]\n",
    "            guided_es.guided_es(actor, partial, args.np_ges, args.std_ges, args.alpha)\n",
    "            \n",
    "        actor_opt.step()\n",
    "    \n",
    "    for p, p_bar in zip(actor.parameters(), actor_bar.parameters()):\n",
    "        p_bar.data[:] = p.data\n",
    "        \n",
    "    if args.ckpt_every > 0 and (i + 1) % args.ckpt_every == 0:\n",
    "        ckpt(actor, critic, actor_opt, critic_opt, i)\n",
    "        \n",
    "    if args.report_every > 0 and (i + 1) % args.report_every == 0:\n",
    "        report(actor, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
