{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import torch as th\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "N_CLASSES = 2\n",
    "N_ITERATIONS = 500\n",
    "SAMPLE_SIZE = 16\n",
    "P = (1 / N_CLASSES,) * N_CLASSES\n",
    "L = lambda y_bar, y: my.nd_f_beta(th.max(y_bar, 1)[1], y, N_CLASSES)\n",
    "cuda = True\n",
    "if cuda:\n",
    "    th.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_simplex(n, d):\n",
    "    x = th.sort(th.rand((n, d - 1)) * 0.001, 1)[0]\n",
    "    return th.cat((x, th.ones(n, 1)), 1) - th.cat((th.zeros(n, 1), x), 1)\n",
    "\n",
    "def rand_sample(n, d, p):\n",
    "    y = Variable(th.from_numpy(npr.choice(np.arange(d), n, True, p)).long())\n",
    "    y_onehot = my.onehot(y, d)\n",
    "    y_bar = Variable(rand_simplex(n, d))\n",
    "    return th.cat((y_onehot, y_bar), 1), L(y_bar, y)\n",
    "\n",
    "def rand_batch(m, n, d, p):\n",
    "    x, y = zip(*tuple(rand_sample(n, d, p) for i in range(m)))\n",
    "    x = tuple(z.view(1, -1) for z in x)\n",
    "    y = tuple(z.view(1, 1) for z in y)\n",
    "    return th.cat(x, 0), th.cat(y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = my.RN(SAMPLE_SIZE, 2 * N_CLASSES, (512,) * 3 + (1,), F.relu)\n",
    "if cuda:\n",
    "    critic.cuda()\n",
    "critic_optim = Adam(critic.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO random sample size\n",
    "# TODO regularize critic\n",
    "for i in range(N_ITERATIONS):\n",
    "    x, y = rand_batch(BATCH_SIZE, SAMPLE_SIZE, N_CLASSES, P)\n",
    "    if cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "    mse = 1e10\n",
    "    while float(mse) > 1e-1:\n",
    "        mse = th.mean((critic(x) - y) ** 2, 0)\n",
    "        critic_optim.zero_grad()\n",
    "        mse.backward()\n",
    "        critic_optim.step()\n",
    "#     print(float(mse))\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        x, y = rand_batch(64, SAMPLE_SIZE, N_CLASSES, P)\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        error = th.mean(th.abs(critic(x) - y), 0)\n",
    "        print('[iteration %d]error: %f' % (i + 1, error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
